# -*- coding: utf-8 -*-
"""Q1_LVADSUSR115_ShaktiIA2..ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AlIkY_pcUj9Yf4axWn1e0sAEbm-w-m4u
"""

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings("ignore")
from sklearn.cluster import KMeans
import pandas as pd
import numpy as np

from sklearn.preprocessing import MinMaxScaler
from matplotlib import pyplot as plt
# %matplotlib inline

import pandas as pd
data = pd.read_csv('/content/winequality-red.csv')
data.head()

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler

import pandas as pd
data = pd.read_csv('/content/winequality-red.csv')
data.head()

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler

# a. Handle missing values
print(data.isnull().sum())
imputer = SimpleImputer(strategy='mean')
data[['fixed acidity', 'residual sugar', 'pH' , 'volatile acidity' , 'citric acid' , 'sulphates','chlorides','free sulfur dioxide' ]] = imputer.fit_transform(data[['fixed acidity', 'residual sugar', 'pH', 'volatile acidity' , 'citric acid' , 'sulphates','chlorides','free sulfur dioxide']])

# Outlier Handling
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
outliers = (data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))
data[outliers] = np.where(data[outliers] < (Q1 - 1.5 * IQR), Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)

# Now data contains the outliers replaced by the upper or lower bound values

# b. Data Transformation
data['quality'] = data['quality'].apply(lambda x: 'bad' if x <= 6 and x>=3 else 'good')

# c. Encoding data and data is already balanced and there is no churn variable
label_encoder = LabelEncoder()
data['quality'] = label_encoder.fit_transform(data['quality'])

# d.Feature selection and data cleaning
features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides',
            'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']
target = 'quality'

# e.Data Splitting
X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# f.Model development
k_values = [3, 5, 7, 9]
for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train_scaled, y_train)
    y_pred = knn.predict(X_test_scaled)

    # g. Model Evaluation
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)

    print(f'KNN with K={k}:')
    print(f'Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}')



























